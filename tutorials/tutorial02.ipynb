{
 "metadata": {
  "name": "",
  "signature": "sha256:2f968554c5919ef460c635d00cb4c72081e6c25ff6a9d0f6d68782a4e162c7d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementing custom Viewpoints"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#Implementing-a-File-Loader\">Implementing a File Loader</a>\n",
      "\n",
      "<a href=\"#Implementing-a-Viewpoint\">Implementing a Viewpoint</a>\n",
      "\n",
      "<a href=\"#Implementing-an-Interface\">Implementing an Interface</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Viewpoints are a flexible concept of the lrn2 framework which allow for a reusable format-specific loading of files and domain-specific conversion of data. A <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.formats.html\">format-specific Interface</a> knows how data should be read from a certain filetype and provides interfaces from which <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.domain.html\">domain-specific Viewpoints</a> may collect the data in a standardized format and convert it into a representation suited as input for NNs (e.g. binary representation), or defines how the data should be plotted.\n",
      "\n",
      "In this tutorial, we describe how to define such <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.formats.html\">interfaces</a> and <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.domain.html\">viewpoints</a> through the example of symbolic music (MIDI). We also decribe the file loader (e.g. <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.formats.html?highlight=load_#lrn2.data.formats.midi.load_midi_files\">load_midi_files()</a>), which is used to load the actual data into the framework in the first place."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementing a File Loader"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#Implementing-custom-Viewpoints\">top</a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import necessary modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lrn2.data.formats.midi import load_midi\n",
      "from lrn2.util.utils import read_input_filelist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 1: GeForce GT 640\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The example below shows how a simple file loader for MIDI files is to be defined. It receives a pointer to one or multiple files which it resolves to several instance sets and their corresponding labels. In the case of MIDI files, a label might be a genre or a key annotation. After instantiating a <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#module-lrn2.data.corpus\">Corpus</a>, data can be added to the <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#module-lrn2.data.corpus\">Corpus</a> by calling its method <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#lrn2.data.corpus.Corpus.load_files\">load_files(filenames)</a>. Therefore, the file loader is not restricted on what it expects as an input parameter (the file loader might even generate data on the fly, and <code>filenames</code> might then be parameters to that process, or <code>None</code>)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_midi_files(filenames):\n",
      "    for fn, label in filenames.iteritems():\n",
      "        yield (load_midi(fn), label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that a <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#module-lrn2.data.corpus\">Corpus</a> stores two different types of data. One is a list of <b>instance sets</b>, which in our example is a list of songs as returned by the file loader. The other data set is created when Corpus.<a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#lrn2.data.corpus.Corpus.set_to_ngram\">set_to_ngram()</a> is called, and those ngrams are the actual <b>training instances</b> which will be presented to the Neural Net (NN). How an <b>instance set</b> is converted into a <b>training instance</b> representation is to be defined in the method <code>raw_to_binary()</code>, to be implemented in the actual <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.domain.html\">viewpoint</a> (as described in <a href=\"#Implementing-a-Viewpoint\">Implementing a Viewpoint</a>). This method, however, should NOT split instance sets into ngrams, what is done by the <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#module-lrn2.data.corpus\">Corpus</a> class, based on the parameter <code>ngram_size</code> in <a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html?highlight=set_to_ngram#lrn2.data.corpus.Corpus.set_to_ngram\">set_to_ngram(ngram_size)</a>.\n",
      "\n",
      "Note that in the upper example <code>filenames</code> is a dictionary of filename/label pairs. Let us assume there is a csv file, where the first column consists of filenames and the second column consists of the corresponding labels (tab-separated). In this case, we can load such a file with the following line of code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filenames = read_input_filelist(\"./data/midi/midi_filelist.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementing a Viewpoint"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#Implementing-custom-Viewpoints\">top</a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import necessary modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import abc\n",
      "\n",
      "from lrn2.data.domain.viewpoint import ViewPoint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As described above, a viewpoint is domain-specific, which means it does not care about where the data comes from (in our case it comes from MIDI files), but it expects standardized data on which it provides a view at. This view is then to be converted to a representation suited as input to NNs. Music is a good example for the neccesity of viewpoints, as it is common that in this domain the input to NNs is a concatenated vector of different views onto the raw data. For example, a melodic line can be split into sequences of absolute pitch, relative pitch, pitch class, contour, duration, octave, inter-onset-interval, offset-onset-intervals, and many more.\n",
      "\n",
      "As an example, we create a viewpoint for pitch class, which takes the melodic pitch information from the data and outputs <b>melodic pitch % 12</b> (i.e. it removes the octave information)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Derived from ViewPoint\n",
      "class PitchClassVP(ViewPoint):\n",
      "    # Necessary for defining abstract methods\n",
      "    __metaclass__ = abc.ABCMeta\n",
      "\n",
      "    def __init__(self, modulo=12):\n",
      "        super(PitchClassVP, self).__init__()\n",
      "        self.modulo=modulo\n",
      " \n",
      "    # The (domain-specific) viewpoint expects the (format-specific) interface\n",
      "    # to implement this method\n",
      "    @abc.abstractmethod\n",
      "    def get_pitch_from_raw_data(self, data):\n",
      "        raise NotImplementedError(\"Method supposed to be implemented in the \"\n",
      "                                  \"format specific interface.\")\n",
      "\n",
      "    @property\n",
      "    def size(self):\n",
      "        return self.modulo\n",
      "\n",
      "    # Convert the raw data (here: MIDI table of one song)\n",
      "    # into a binary (one-out-of-n) pitch class representation.\n",
      "    def raw_to_repr(self, raw_data):\n",
      "        # get an absolute pitch sequence from the interface\n",
      "        # (the interface knows where pitch is encoded in\n",
      "        # the MIDI table).\n",
      "        pitch_abs = self.get_pitch_from_raw_data(raw_data)\n",
      "        \n",
      "        # modulo calculation\n",
      "        pitch_class = np.mod(pitch_abs, self.modulo)\n",
      "        \n",
      "        # Create an empty binary representation in the\n",
      "        # appropriate shape. The resulting matrix is of size \n",
      "        # N (time steps in song) x 12 (size of one timestep)\n",
      "        N = len(pitch_class)\n",
      "        data = np.zeros((N, self.size), dtype = np.bool)\n",
      "        # Set True (1) according to the pitch class values\n",
      "        data[range(N),pitch_class] = 1\n",
      "        # Return with a sparse matrix\n",
      "        return sp.csr_matrix(data, shape = data.shape)\n",
      "\n",
      "    # Define how the binary data should be plotted\n",
      "    def repr_to_visual(self, binary_data):\n",
      "        # Flip the matrix horizontally\n",
      "        return np.fliplr(binary_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most important method in the viewpoint class is <code>raw_to_repr</code>. When the Corpus receives raw data from the file loader, it asks each viewpoint how that raw data should be represented as input to the NN by calling that method. The result does not necessarily have to be binary, but what the Corpus expects as return value for an instance set is a matrix (sparse or ndarray), with vertically concatenated rows, where each row represents a view at one timestep of the data. In case the data is not sequential, each row represents one training instance and the <code>ngram_size</code> (<a href=\"http://lrn2cre8.ofai.at/lrn2/doc/lrn2.data.html#lrn2.data.corpus.Corpus.set_to_ngram\">set_to_ngram(ngram_size)</a>, see <b>Tutorial 1</b>) should be set to 1."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementing an Interface"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#Implementing-custom-Viewpoints\">top</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next example shows how the interface between the data imported by the file loader and the viewpoint can be defined."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MIDIInterface(object):\n",
      "    # Implement abstract methods\n",
      "    def get_pitch_from_raw_data(self, data):\n",
      "        # The interface knows that pitch is encoded\n",
      "        # in column 0 of the MIDI table\n",
      "        return data[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we derive from both the <a href=\"#Implementing-an-Interface\">Interface</a> and the <a href=\"#Implementing-a-Viewpoint\">Viewpoint</a> to retrieve a class which has all methods and properties of the viewpoint with the abstract method <code>get_pitch_from_raw_data()</code> implemented:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MidiVP(MIDIInterface, PitchClassVP): pass "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we instantiate a Corpus, the file loader as well as the class MidiVP is used as parameters for the Corpus constructor. Note that the constructor expects a list of viewpoints. From here, see <b>Tutorial 1</b> for next steps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lrn2.data.corpus import Corpus\n",
      "\n",
      "corpus = Corpus(load_midi_files, (MidiVP,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}